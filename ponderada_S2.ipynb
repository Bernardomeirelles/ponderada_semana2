{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Carregamento e Seleção de Dados\n",
        "## Primeiro carregamos o dataset e selecionamos 10 frases para demonstração"
      ],
      "metadata": {
        "id": "PFw045N7C5U9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jDR3b-7C3Yi",
        "outputId": "a61d7140-da4e-4e3a-ad5f-1d078b838950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.stem import RSLPStemmer\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('rslp')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ID da  planilha no Google Sheets\n",
        "sheet_id = \"1SNV2AooYAxRZO0ubQXdWc6uCnxqk9axb\"\n",
        "\n",
        "# URL de exportação direta para XLSX\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=xlsx\"\n",
        "\n",
        "try:\n",
        "    # Carrega diretamente do Google Sheets\n",
        "    df = pd.read_excel(url)\n",
        "    print(\"Arquivo carregado com sucesso a partir do link do Google Sheets!\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao carregar o arquivo: {e}\")\n",
        "    raise\n",
        "df = df.dropna(subset=['Notícia'])  # Remover linhas com texto faltante\n",
        "amostras = df.sample(10, random_state=42)['Notícia'].tolist()  # 10 frases aleatórias\n",
        "\n",
        "print(\"Exemplos brutos:\")\n",
        "for i, texto in enumerate(amostras[:3], 1):  # Mostrar 3 primeiras para ilustração\n",
        "    print(f\"\\nTexto {i} original:\\n{texto}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbC1P-87Dn2o",
        "outputId": "40845b0b-a4e4-435a-f763-09bc0f748113"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo carregado com sucesso a partir do link do Google Sheets!\n",
            "Exemplos brutos:\n",
            "\n",
            "Texto 1 original:\n",
            "A Nike lançou a Phantom Luna, a chuteira feminina, às vésperas do amistoso da Seleção Brasileira Feminina de Futebol que bateu o Chile por 4 x 0 neste domingo (2), em Brasília (DF).\n",
            "\n",
            "A chuteira marca o protesto da super atacante brasileira Marta, que fez campanha na Copa do Mundo Feminina de 2019, pela visibilidade do torneio e igualdade com os atletas masculinos.\n",
            "\n",
            "Sete vezes eleita a melhor jogadora do mundo, Marta transformou a chuteira preta, sem detalhes, em símbolo colorido de igualdade de gênero no futebol. No Mundial da Austrália e da Nova Zelândia, entre julho e agosto, as jogadoras patrocinadas pela Nike usarão, pela primeira vez,  a chuteira.\n",
            "\n",
            "Comercial\n",
            "A chuteira\n",
            "\n",
            "A Nike, que também responsável por fornecer os uniformes da Seleção Brasileira, informou que, desde a pesquisa até o design, passando pela etapa de testes, as jogadoras estiveram sempre no centro do processo.\n",
            "\n",
            "Com a Phantom Luna, a Nike promete oferecer uma chuteira desenhada para as mulheres, com um padrão circular de travas, assim como ajuste.\n",
            "\n",
            "Atualmente, metade das 26 jogadoras convocadas pela técnica Pia Sundhage, incluindo as três suplentes, são calçadas pela marca norte-americana. A atacante Debinha foi convidada para estrelar a campanha.\n",
            "\n",
            "Siga aqui o canal do SóNotíciaBoa no WhatsApp\n",
            "De acordo com a Nike, a chuteira custará em torno de R$ 2.299,99, na cor branca com laranja e preta.\n",
            "\n",
            "As brasileiras que devem usar\n",
            "\n",
            "Bruninha\n",
            "Rafaelle\n",
            "Kerolin\n",
            "Luana\n",
            "Adriana\n",
            "Ana Vitória\n",
            "Ary Borges\n",
            "Andressa Alves\n",
            "Bia Zaneratto\n",
            "Debinha\n",
            "Tainara (suplente)\n",
            "Aline Gomes (suplente)\n",
            "Angelina (suplente) Apoio extra\n",
            "\n",
            "No momento em que ocorre o lançamento da chuteira, o governo brasileiro anuncia apoio ao futebol feminino. Ontem (1º) o presidente Luiz Inácio Lula e uma comitiva de autoridades se reuniram com as jogadoras no Estádio Mané Garrincha, em Brasília.\n",
            "\n",
            "Também estiveram presentes a ministra das Mulheres, Cida Gonçalves, da Igualdade Racial, Anielle Franco, o presidente da Confederação Brasileira de Futebol, Ednaldo Rodrigues, e o diretor-presidente do estádio.\n",
            "\n",
            "Lula cumprimentou as jogadoras, recebeu a camisa 10 da Seleção Feminina e a camisa preta da Seleção Masculina com o nome do jogador Vini Jr., vítima de racismo recente na Europa.\n",
            "\n",
            "“Nós precisamos garantir a prática de esportes da mesma proporção dos homens, desde a escola até a vida adulta. Quando eu escolhi a Ana Moser para ministra do Esporte, a primeira coisa que ela me disse foi que precisávamos cuidar da prática de esporte feminina”, disse o presidente.\n",
            "\n",
            "Texto 2 original:\n",
            "A 6ª câmara do Conselho de Ética do Conselho Nacional de Autorregulamentação Publicitária julgou na última terça-feira, 21, representação contra a Empiricus Research. O colegiado aprovou, por unanimidade, recomendação de \"sustação agravada por advertência ao anunciante\" a seis propagandas da empresa, incluindo o vídeo sobre a personagem Bettina.\n",
            "\n",
            "Caso Bettina\n",
            "\n",
            "\"Oi. Meu nome é Bettina, eu tenho 22 anos e 1 milhão e 42 mil reais de patrimônio acumulado\", diz Bettina na propaganda, afirmando que começou a investir aos 19 anos com aplicação inicial de R$ 1.520,00.\n",
            "\n",
            "No anúncio, Bettina diz ainda que, investindo nas mesmas ações, o lucro do investidor será proporcionalmente o mesmo que ela obteve. Relembre:\n",
            "\n",
            "Representação\n",
            "\n",
            "A representação 63/19  foi aberta no Conar em março. Na ocasião, o órgão informou que recebeu \"numerosas denúncias de consumidores\" que questionaram a veracidade das afirmações contidas nos vídeos.\n",
            "\n",
            "Ao analisar o caso na última terça-feira, 21, o colegiado aprovou a recomendação de sustação dos anúncios, incluindo o vídeo sobre Bettina.\n",
            "\n",
            "\"Representação Nº 063/19, \"Empiricus Research Publicações - Oi. Meu nome é Bettina. Tenho 22 anos e 1.042.000,00 reais de patrimônio acumulado\"; \"Dobre seu salário em tempo recorde\"; \"+251 todos os dias na sua conta\"; \"Receba todo mês R$1.823,53 de aluguel\"; \"Milionário com ações\" e \"O dobro ou nada\". Resultado: sustação agravada por advertência ao anunciante, por unanimidade.\"\n",
            "\n",
            "Multa\n",
            "\n",
            "Em abril, o Procon/SP decidiu aplicar multar à Empiricus por veiculação de publicidade enganosa em virtude do anúncio sobre Bettina. A multa, aplicada mediante procedimento administrativo, foi fixada entre um mínimo de R$ 650 e o máximo de R$ 9 milhões.\n",
            "\n",
            "\n",
            "\n",
            "Texto 3 original:\n",
            "A Libbs Farmacêutica abre, na quarta-feira (9), as inscrições para a quarta edição do Linna, seu programa de inovação aberta. Com o objetivo de impulsionar parcerias com startups, scale-ups e pequenas empresas, o Linna busca soluções inovadoras para os desafios do setor de saúde.\n",
            "\n",
            "Para este ano o Linna tem como foco a busca por soluções que beneficiam pacientes, cuidadores e profissionais de saúde. Foram definidos cinco desafios, que vão desde o aparecimento dos primeiros sintomas até manutenção da saúde em diversos momentos da vida. Os desafios são: 1.Primeiros sintomas, primeiros desafios – Encontrando a especialidade certa - a busca por soluções voltadas para o paciente no “momento zero” — o instante em que uma pessoa começa a perceber os primeiros sintomas. O objetivo é facilitar a jornada do paciente ao encontrar soluções para reconhecer os sinais iniciais e determinar qual especialidade médica procurar.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Técnica 1: Tokenização (usando biblioteca)\n",
        "# **Objetivo:** Dividir textos em unidades significativas (palavras/pontuação)"
      ],
      "metadata": {
        "id": "ORyvNqGNEujf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Técnica 1: Tokenização (usando biblioteca)\n",
        "# **Objetivo:** Dividir textos em unidades significativas (palavras/pontuação)\n",
        "\n",
        "# %%\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenizacao(texto):\n",
        "    return word_tokenize(texto.lower(), language='portuguese')\n",
        "\n",
        "# Aplicar em todos os textos\n",
        "tokens = [tokenizacao(texto) for texto in amostras]\n",
        "\n",
        "print(\"\\nExemplo de tokenização:\")\n",
        "print(f\"Antes: {amostras[0][:50]}...\")\n",
        "print(f\"Depois: {tokens[0][:5]}...\")  # Mostrar primeiros 5 tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIdtVKCEEvIe",
        "outputId": "ae98a99e-fe05-40b8-c39f-ecf51e4d6958"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exemplo de tokenização:\n",
            "Antes: A Nike lançou a Phantom Luna, a chuteira feminina,...\n",
            "Depois: ['a', 'nike', 'lançou', 'a', 'phantom']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Técnica 2: Remoção de Stopwords (implementação manual)\n",
        "# **Objetivo:** Remover palavras comuns que não agregam significado\n",
        "\n",
        "\n",
        "# Lista customizada criada manualmente (implementação from scratch)\n",
        "stopwords_personalizadas = [\n",
        "    'de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'para', 'com', 'uma', 'os',\n",
        "    'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele'\n",
        "]\n"
      ],
      "metadata": {
        "id": "_pdLSzWaGo8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_personalizadas = [\n",
        "    'de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'para', 'com', 'uma', 'os',\n",
        "    'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele'\n",
        "]\n",
        "\n",
        "def remover_stopwords(tokens):\n",
        "    return [token for token in tokens if token not in stopwords_personalizadas]\n",
        "\n",
        "# Aplicar filtro\n",
        "tokens_sem_stopwords = [remover_stopwords(doc) for doc in tokens]\n",
        "\n",
        "print(\"\\nExemplo de remoção de stopwords:\")\n",
        "print(f\"Antes: {tokens[0][:10]}...\")\n",
        "print(f\"Depois: {tokens_sem_stopwords[0][:10]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK0P-7FiOAbC",
        "outputId": "cd4d6d3d-9f9b-45c3-f6d7-933269d00c14"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exemplo de remoção de stopwords:\n",
            "Antes: ['a', 'nike', 'lançou', 'a', 'phantom', 'luna', ',', 'a', 'chuteira', 'feminina']...\n",
            "Depois: ['nike', 'lançou', 'phantom', 'luna', ',', 'chuteira', 'feminina', ',', 'às', 'vésperas']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Técnica 3: Radicalização (Stemming)\n",
        "## **Objetivo:** Reduzir palavras à sua forma base"
      ],
      "metadata": {
        "id": "UeRF5Hm4OSk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = RSLPStemmer()\n",
        "\n",
        "def aplicar_stemming(tokens):\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "# Processar textos\n",
        "tokens_stemizados = [aplicar_stemming(doc) for doc in tokens_sem_stopwords]\n",
        "\n",
        "print(\"\\nExemplo de stemming:\")\n",
        "print(f\"Antes: {tokens_sem_stopwords[0][:10]}...\")\n",
        "print(f\"Depois: {tokens_stemizados[0][:10]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR9iF_EpORgR",
        "outputId": "3e0c41ae-9e20-46d4-bd00-2f47dd4cebc5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exemplo de stemming:\n",
            "Antes: ['nike', 'lançou', 'phantom', 'luna', ',', 'chuteira', 'feminina', ',', 'às', 'vésperas']...\n",
            "Depois: ['nik', 'lanç', 'phantom', 'lun', ',', 'chut', 'feminin', ',', 'às', 'vésp']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Pipeline Completo de Pré-processamento\n",
        "# Combinação de todas as etapas em um fluxo automatizado\n"
      ],
      "metadata": {
        "id": "LiB9dqXeW1wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline_preprocessamento(texto):\n",
        "    # Etapas sequenciais\n",
        "    tokens = tokenizacao(texto)\n",
        "    tokens = remover_stopwords(tokens)\n",
        "    tokens = aplicar_stemming(tokens)\n",
        "    return tokens\n",
        "\n",
        "# Aplicar em toda a amostra\n",
        "textos_processados = [pipeline_preprocessamento(texto) for texto in amostras]"
      ],
      "metadata": {
        "id": "xZJFqA5xW2XW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Resultados Finais\n",
        "# Comparação entre textos originais e pré-processados\n",
        "\n",
        "# %%\n",
        "print(\"\\nComparação final:\")\n",
        "for i in range(3):  # Mostrar 3 exemplos\n",
        "    print(f\"\\nOriginal ({i+1}):\\n{amostras[i][:70]}...\")\n",
        "    print(f\"Pré-processado: {textos_processados[i][:10]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO7GUXmXW-ca",
        "outputId": "bfc0f586-6355-4ca0-ec58-6ff4231b725f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparação final:\n",
            "\n",
            "Original (1):\n",
            "A Nike lançou a Phantom Luna, a chuteira feminina, às vésperas do amis...\n",
            "Pré-processado: ['nik', 'lanç', 'phantom', 'lun', ',', 'chut', 'feminin', ',', 'às', 'vésp']...\n",
            "\n",
            "Original (2):\n",
            "A 6ª câmara do Conselho de Ética do Conselho Nacional de Autorregulame...\n",
            "Pré-processado: ['6ª', 'câm', 'conselh', 'étic', 'conselh', 'nacion', 'autorregulament', 'publicitár', 'julg', 'últ']...\n",
            "\n",
            "Original (3):\n",
            "A Libbs Farmacêutica abre, na quarta-feira (9), as inscrições para a q...\n",
            "Pré-processado: ['libb', 'farmac', 'abr', ',', 'quarta-f', '(', '9', ')', ',', 'inscr']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Conclusão do Colab: Pré-processamento de Textos para Análise de Sentimentos\n",
        "\n",
        "O notebook estruturou um pipeline de pré-processamento de textos utilizando três técnicas fundamentais para análise de sentimentos em português: **tokenização**, **remoção manual de stopwords** e **stemming**. O processo foi aplicado sobre 10 frases selecionadas aleatoriamente da base de dados do projeto, garantindo diversidade e evitando sobreposição com outros grupos.\n",
        "\n",
        "\n",
        "### Resumo das Técnicas Utilizadas\n",
        "\n",
        "- **Tokenização:**  \n",
        "  Os textos foram divididos em tokens (palavras e pontuações), facilitando a manipulação e análise subsequente. O uso de uma biblioteca especializada (NLTK) garantiu precisão na segmentação linguística, essencial para qualquer pipeline de PLN.\n",
        "\n",
        "- **Remoção de Stopwords (implementação manual):**  \n",
        "  Uma lista customizada de palavras comuns foi criada e aplicada sem o uso de bibliotecas prontas, atendendo ao requisito de implementação \"from scratch\". Isso removeu termos que não agregam significado, tornando o texto mais relevante para análise sem ruídos.\n",
        "\n",
        "- **Stemming:**  \n",
        "  Utilizando o RSLPStemmer da NLTK, as palavras foram reduzidas à sua forma radical, agrupando diferentes variações de um mesmo termo e melhorando a generalização dos modelos de machine learning.\n",
        "\n",
        "\n",
        "### Funcionamento do Pipeline\n",
        "\n",
        "O pipeline sequencial automatiza as três etapas, permitindo o pré-processamento consistente de qualquer texto da base. O resultado é um conjunto de tokens representativos, livres de ruídos e prontos para alimentar modelos de análise de sentimentos ou outras tarefas de PLN.\n",
        "\n",
        "\n",
        "### Resultados Observados\n",
        "\n",
        "A comparação entre os textos originais e os pré-processados demonstra a eficácia das técnicas:\n",
        "\n",
        "- Redução significativa de palavras irrelevantes.\n",
        "- Normalização dos termos, facilitando a identificação de padrões e sentimentos.\n",
        "- Preparação dos dados para algoritmos de aprendizado de máquina, com menor dimensionalidade e maior qualidade semântica.\n",
        "\n",
        "\n",
        "### Próximos Passos Sugeridos\n",
        "\n",
        "- Ampliar a lista de stopwords para abranger termos específicos do domínio do projeto.\n",
        "- Testar técnicas mais avançadas, como lematização, para maior precisão na normalização.\n",
        "- Incluir tratamento de negações e elementos não textuais (como emojis), que podem ser relevantes para análise de sentimentos em contextos informais."
      ],
      "metadata": {
        "id": "VxSh2V5jf4t3"
      }
    }
  ]
}